---
title: "Data Creation"
author: "Erin M. Buchanan"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(semanticprimeR)
library(dplyr)
library(rio)
library(tidyr)
```

## Data

Questions: 

1) Do we want to use the original (more strict) scoring for accuracy for inclusion or the revised (less strict) scoring? 
  - original accuracy: correct / trials seen
  - revised: correct / trials answered --> more data
  
Note: after running this, I turned the chunk off so it's not running over and over. 

```{r eval = F}
# a list of datasets
data(primeData)
primeData.filter <- primeData %>% 
  filter(grepl("prime_summary.csv", filename)) %>% 
  filter(!grepl("answered", filename))

data.files <- lapply(primeData.filter$location, import)
lang.length <- lapply(data.files, nrow)

full.data <- bind_rows(data.files) %>% 
  mutate(language = rep(primeData.filter$language, times = lang.length))

matching.data <- import(primeData %>% 
                          filter(language == "all") %>% 
                          pull(location))
```

```{r eval = F}
# merge and write by language
languages <- unique(full.data$language)

for (lang in languages){
  
  if (lang == "en") {
    columns <- c("en_cue", "en_target", 
                paste0(lang, "_target_word_unique"),
                paste0(lang, "_word_combo_related"), 
                paste0(lang, "_word_combo_unrelated"),
                paste0(lang, "_cue_word_related"),
                paste0(lang, "_cue_word_unrelated")
    )
  } else {
    columns <- c("en_cue", "en_target", 
            paste0(lang, "_cue"),
            paste0(lang, "_target"),
            paste0(lang, "_target_word_unique"),
            paste0(lang, "_word_combo_related"), 
            paste0(lang, "_word_combo_unrelated"),
            paste0(lang, "_cue_word_related"),
            paste0(lang, "_cue_word_unrelated")
            )
  }

  temp <- full.data %>% 
    filter(language == lang) %>% 
    mutate(target_word_unique = tolower(target_word_unique)) %>% 
    left_join(
      matching.data[ , columns],
      by = c("target_word_unique" = paste0(lang, "_target_word_unique"))
    ) 

  cat(lang, " ", nrow(temp), " ", sum(is.na(temp$en_cue)), " \n")
  
  export(temp, paste0("priming_data/", lang, "_priming.csv"))
}

# fix extras in korean
ko_fix <- import("priming_data/ko_priming.csv") %>% 
  filter(!is.na(avgRT_related))
nrow(ko_fix)
export(ko_fix,"priming_data/ko_priming.csv", row.names = F)
```

Notes:
- Korean has too many rows due to an error in matching. I excluded the extra ones. 
- Not all languages have enough data to calculate good priming scores - we used target answered = 50 but we may consider figuring out a different criteria for this project. 
