---
title: "Data Creation"
author: "Erin M. Buchanan"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(semanticprimeR)
library(dplyr)
library(rio)
library(tidyr)
```

## Data

Questions: 

1) Do we want to use the original (more strict) scoring for accuracy for inclusion or the revised (less strict) scoring? 
  - original accuracy: correct / trials seen
  - revised: correct / trials answered --> more data
  
  
Note: after running this, I turned the chunk off so it's not running over and over. 

```{r eval = F}
# a list of datasets
data(primeData)
primeData.filter <- primeData %>% 
  filter(grepl("prime_summary.csv", filename)) %>% 
  filter(!grepl("answered", filename))

data.files <- lapply(primeData.filter$location, import)
lang.length <- lapply(data.files, nrow)

full.data <- bind_rows(data.files) %>% 
  mutate(language = rep(primeData.filter$language, times = lang.length))

matching.data <- import(primeData %>% 
                          filter(language == "all") %>% 
                          pull(location))
```

```{r eval = F}
# merge and write by language
languages <- unique(full.data$language)

for (lang in languages){
  
  if (lang == "en") {
    columns <- c("en_cue", "en_target", 
                paste0(lang, "_target_word_unique"),
                paste0(lang, "_word_combo")
    )
    lang2 <- "en"
  } else if (lang == "br_pt") {
    columns <- c("en_cue", "en_target", 
              paste0("pt_br", "_cue"),
              paste0("pt_br", "_target"),
              paste0("pt_br", "_target_word_unique"),
              paste0("pt_br", "_word_combo")
              )
    lang2 <- "pt_br"
  } else {
    columns <- c("en_cue", "en_target", 
            paste0(lang, "_cue"),
            paste0(lang, "_target"),
            paste0(lang, "_target_word_unique"),
            paste0(lang, "_word_combo")
            )
    lang2 <- lang
  }

  
  temp <- full.data %>% 
    filter(language == lang) %>% 
    left_join(
      matching.data[ , columns],
      by = c("target_word_unique" = paste0(lang2, "_target_word_unique"))
    )
  
  cat(lang, " ", nrow(temp), " \n")
  
  export(temp, paste0("data/", lang, "_priming.csv"))
}
```

Notes:
- Korean has too many rows due to an error in matching. You can exclude the NA values in the priming columns. 
- Not all languages have enough data to calculate good priming scores - we used target answered = 50 but we may consider figuring out a different criteria for this project. 